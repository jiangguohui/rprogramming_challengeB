---
title: "ChallengeB"
author: "Guohui Jiang; Jiayin Zhai"
date: "11/25/2017"
output: word_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load.libraries <- c('tidyverse', 'randomForest','caret','data.table','np')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependencies = TRUE)
sapply(load.libraries, require, character = TRUE)
```
Github[__link__](https://github.com/jiangguohui/rprogramming_challengeB). In Task 3B, we need about 6 mins to import the SIREN dataset into out computer.

# Task 1B - Predicting house price in Ames, Lowa (continued)
## Step 1
The intuition behind Random Forests: we randomly split the training data into some subsamples, then we will use models to predict the observations of each subsample. The final prediction should be a function of each prediction. For example, we have 10,000 observations in the training data, then we randomly draw 100 subsamples from it. We will run a model on one subsample. It will repeat the process 100 times and then make a final prediction on each observation. Final prediction is a function of each prediction. This final prediction can simply be the mean of each prediction, or we can pick final prediction based on majority rule.

## Step 2

```{r, include=FALSE}
# importing training data
train <- read.csv("train.csv")
test <- read.csv("test.csv")
library(tidyverse)

# remove variables with a lot of missing values
remove.vars <- train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist
train <- train %>% select(- one_of(remove.vars))

# for remaining variables, only keep rows without NAs
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

train <- train %>% filter(is.na(GarageType) == FALSE, is.na(MasVnrType) == FALSE, is.na(BsmtFinType2) == FALSE, is.na(BsmtExposure) == FALSE, is.na(Electrical) == FALSE)

# make sure it's all clean : Yes
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)

# running linear regression model
lm_model_1 <- lm(SalePrice ~ ., data= train)
summary(lm_model_1)

sum_lm_model_1 <- summary(lm_model_1)$coefficients #take only the table of coefficients and t stats and pvalues
class(sum_lm_model_1) #is a matrix
significant.vars <- row.names(sum_lm_model_1[sum_lm_model_1[,4] <= 0.01,]) #sum_lm_model_1[,4] is the p-value of each coefficient, here then i choose the variables that have coefficients significant at the 1% level

# choose any selection of such variables and run a more parcimonious model
lm_model_2 <- lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train)
summary(lm_model_2)

# prediction of linear model
prediction_lm <-as.data.frame(predict(lm_model_2, test, type="response"))
```
Before the following operations, we first deal with the dataset according to the solutions to Challenge A. __Please change the path when you import dataset.__ We train the data through randomForest, and the features we include are the same as thoses in linear model.
```{r include=FALSE}
# setting the seed
set.seed(7)
# train the data using Random Forests technique
rf <- randomForest(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train)
rf
# show the result of random forests technique
```

## Step 3
We compare the two predictions through descriptive statistics and density distribution. We think they are very similar. See the details in the script.

```{r include=FALSE}
# making predictions on the test data using Random Forests
prediction_rf <- predict(rf, test)
# combining the predictions from the two models
predictions <- cbind(prediction_lm, prediction_rf)
names(predictions) <- c("prediction_lm", "prediction_rf")
# comparizing the predictions of the two models
summary(predictions)
# visualize them
ggplot(data = na.omit(predictions)) + geom_density(mapping = aes(x= prediction_lm), color = 'blue') + geom_density(mapping = aes(x= prediction_rf), color = 'black') + xlab(label = "Predictions")
```

# Task 2B - Overfitting in Machine Learning (continued)
First we simulate the data and split it into training and testing as we did in Challenge A.

```{r simulate, include=FALSE}
# Simulating an overfit
# True model : y = x^3 + epsilon
set.seed(1)
Nsim <- 150
b <- c(0,1)
x0 <- rep(1, Nsim)
x1 <- rnorm(n = Nsim)

X <- cbind(x0, x1^3)
y.true <- X %*% b

eps <- rnorm(n = Nsim)
y <- X %*% b + eps

df <- tbl_df(y[,1]) %>% rename(y = value) %>% bind_cols(tbl_df(x1)) %>% rename(x = value) %>% bind_cols(tbl_df(y.true[,1])) %>% rename(y.true = value)
# Split sample into training and testing, 80/20
training.index <- createDataPartition(y = y, times = 1, p = 0.8)
df <- df %>% mutate(which.data = ifelse(1:n() %in% training.index$Resample1, "training", "test"))

training <- df %>% filter(which.data == "training")
test <- df %>% filter(which.data == "test")
```

## Step 1-3
See the details in the script. See the figure in the following pages.
```{r, include=FALSE}
# Train local linear model y ~ x on training, using default low flexibility (high bandwidth)
ll.fit.lowflex <- npreg(y ~ x, data = training, method = "ll", bws = 0.5)
```

```{r, include=FALSE}
# Train local linear model y ~ x on training, using default low flexibility (high bandwidth)
ll.fit.highflex <- npreg(y ~ x, data = training, method = "ll", bws = 0.01)
```

```{r, include=FALSE}
training <- training %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = training), y.ll.highflex = predict(object = ll.fit.highflex, newdata = training))
```

## Step 4
The high-flexibility model(blue one) is more variable, and the low-flexibility model(red one) is less biased.

## Step 5
Here the high-flexibility model(blue one) is more variable, but the low-flexibility model is less biased. See the figure in the following pages.

```{r, include=FALSE}
test <- test %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = test), y.ll.highflex = predict(object = ll.fit.highflex, newdata = test))
```

## Step 6-9
See the details in the script.
```{r, include=FALSE}
# Create vector of several bandwidth
bw <- seq(0.01, 0.5, by = 0.001)
```

```{r, include=FALSE}
# Train local linear model y ~ x on training with each bandwidth
llbw.fit <- lapply(X = bw, FUN = function(bw) {npreg(y ~ x, data = training, method = "ll", bws = bw)})
```

```{r, include=FALSE}
# Compute for each bandwidth the MSE-training
mse.training <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = training)
  training %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))
}
mse.train.results <- unlist(lapply(X = llbw.fit, FUN = mse.training))
```

```{r, include=FALSE}
# Compute for each bandwidth the MSE-test
mse.test <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = test)
  test %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))
}
mse.test.results <- unlist(lapply(X = llbw.fit, FUN = mse.test))
```

## Step 10:
```{r, include=FALSE}
mse.df <- tbl_df(data.frame(bandwidth = bw, mse.train = mse.train.results, mse.test = mse.test.results))
```

Conclusion: As the bandwidth increases, the mse on training data always increases, which means as the training model becomes less flexible, it will have a larger MSE, i.e. the model is more biased compared with the true model when it's not flexible.  
However, the mse on testing data first decreases and then increases as the bandwidth increases, which means when the model is very flexible or very not flexible, the predictions are both more biased compared with the true model. Therefore we should not set the bandwidth too low or too high. Especially we should not set the bandwidth too low, in which case the training model is less biased but the predictions are far from the true values.

# Privacy regulation compliance in France

## Step 1
Use fread function to do that.
```{r, include=FALSE}
# extract the online data through fread
cnil <- fread('https://www.data.gouv.fr/s/resources/correspondants-informatique-et-libertes-cil/20171115-183631/OpenCNIL_Organismes_avec_CIL_VD_20171115.csv')
```
```{r, include=FALSE}
head(cnil)
```

## Step 2
We use substr function to get the first two digits of post code, and then we count them and manage them in a nicer form.
```{r, include=FALSE}
# getting the code of department each company belongs to through the first two digits of post code
cnil$depart_code <- substr(cnil$Code_Postal, start = 1, stop = 2)
# calculating the number of organizations with CNIL per department
pre <- cnil %>% count(depart_code)
head(pre)
pre <- as.data.frame(pre[-c(1,2),])
names(pre) <- c('department','organization_nb')
print(pre)
```

## Step 3
__Before importing the SIREN large dataset, please download and extract it.__ To import the large dataset, we split it into 4 parts, and import them separately, and subsequently merge them with the initial dataset. After completing every step, we remove the big dataset and keep the merged ones and then merge all the 4 datasets into 1. Finally, we work on this merged dataset and select the most up-to-date rows for the same siren.  
For each dataset(with around 3000000 observations), the importing needs about 60s. For the whole step it requires less than 10 mins to run. The final dataset we need is *siren_fin*.

```{r message=FALSE, warning=FALSE, include=FALSE}
# define the name
name <- "sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv"
# First we import the first 3000000 rows
data1 <- fread(input = name, nrows = 3000000, header = TRUE)
col.names<-colnames(data1)
# merge the siren subset with cnil data
names(data1)[1] <- 'Siren'
data1$Siren <- as.integer(data1$Siren)
combination1 <- left_join(cnil, data1, by='Siren')
remove(data1)
col.names_new <- colnames(combination1)
```

```{r include=FALSE}
# we do the similar things in the following steps
data2 <- fread(input = name, nrows = 3000000,skip = 3000001, header = TRUE,col.names = col.names)
names(data2)[1] <- 'Siren'
data2$Siren <- as.integer(data2$Siren)
combination2 <- left_join(cnil, data2, by='Siren')
remove(data2)

data3 <- fread(input = name, nrows = 3000000,skip = 6000001, header = TRUE,col.names = col.names)
names(data3)[1] <- 'Siren'
data3$Siren <- as.integer(data3$Siren)
combination3 <- left_join(cnil, data3, by='Siren')
remove(data3)

data4 <- fread(input = name, nrows = 2831175,skip = 9000001, header = TRUE,col.names = col.names)
names(data4)[1] <- 'Siren'
data4$Siren <- as.integer(data4$Siren)
combination4 <- left_join(cnil, data4, by='Siren')
remove(data4)
```

```{r, include=FALSE}
# slecting the most up-to-date rows
siren_new <- rbind(combination1, combination2, combination3, combination4)
siren_fin <- siren_new %>% group_by(Siren) %>% slice(which.max(as.Date(DATEMAJ, '%Y-%m-%d')))
```

## Step 4
```{r, include=FALSE}
represeantation <- c('NN', 'Non-employer units','00','0 employees','01', '1 or 2 employees',  '02' ,'3 to 5 employees',  
'03', '6 to 9 employees', '11', '10 to 19 employees', '12', '20 to 49 employees',  '21', '50 to 99 employees',  '22', '100 to 199 employees',  '31', '200 to 249 employees',  '32', '250 to 499 employees',  '41 ','500 to 999 employees',  '42 ','1,000 to 1,999 employees',  '51', '2,000 to 4,999 employees',  '52', '5,000 to 9,999 employees',  '53', '10,000 employees and more') 
represeantation <- as.data.frame(matrix(data = represeantation,ncol = 2, byrow = TRUE))
colnames(represeantation) <- c("represeantation","meaning")
```
In terms of the number of salaried employees, the distribution of company size is left skewed, which means that there are more companies with less than 50 employees.

```{r echo=FALSE, fig.cap = "Task1 Step3 - Density Functions of two predictions"}
ggplot(data = na.omit(predictions)) + geom_density(mapping = aes(x= prediction_lm), color = 'blue') + geom_density(mapping = aes(x= prediction_rf), color = 'black') + xlab(label = "Predictions")
```

```{r echo=FALSE, fig.cap = "Task2 Step3 - Predictions of ll.fit.lowflex and ll.fit.highflex on training data."}
ggplot(data = training) + geom_point(mapping = aes(x, y)) + geom_line(mapping = aes(x,y.true))+ geom_line(mapping = aes(x,y.ll.lowflex), color='red') + geom_line(mapping = aes(x,y.ll.highflex), color='blue')
```

```{r echo=FALSE, fig.cap = 'Task2 Step5 - Predictions of ll.fit.lowflex and ll.fit.highflex on test data.'}
ggplot(data = test) + geom_point(mapping = aes(x, y)) + geom_line(mapping = aes(x,y.true))+ geom_line(mapping = aes(x,y.ll.lowflex), color='red') + geom_line(mapping = aes(x,y.ll.highflex), color='blue')
```

```{r echo=FALSE, fig.cap = 'Task2 Step 10 - MSE on training and test data for different bandwidth - local linear regression'}
ggplot(data = mse.df)  + geom_line(mapping = aes(bandwidth, mse.train), color='blue')+ geom_line(mapping = aes(bandwidth, mse.test), color='orange') 
```

```{r echo=FALSE, fig.cap = 'Task3 Step 4 - The histogram of the size of the companies that nominated a CIL.'}
# plotting
ggplot(data = siren_fin,mapping = aes(x = as.factor(TEFET))) + geom_bar() + labs(x= "Tranche of salaried employees of the establishment", y='Count')
```
```{r echo=FALSE}
represeantation
```